---
layout: post
title: Blog1 - Databases, queries, and regressions
---

##### In this project, I studied the temperature change pattern among weather stations in some countries around the globe, for instance, those in India and US. I constructed functions to extract the targeted country, month by using SQL grammar and accessing the database created with sqlite. I also familiarized myself with multiple data manipulation and visual representation techniques.

##### This is where I read in the packages. For aesthetic and convenience purposes, I turned off the warning after knowing that there is nothing wrong with other parts of my project.

```python
import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import plotly.express as px
import seaborn as sns
from sklearn import linear_model
import plotly
import warnings
warnings.filterwarnings("ignore")
```

##### PART 1: Read in the data and creating database. After doing so, I read them into a newlu constructed database, called Database_temp. To read in, I also need to construct a connection.
```python
# Load and modify the datasets
temperatures = pd.read_csv("temps.csv")
temperatures["Country_abbrev"] = temperatures["ID"].str[0:2]
countries = pd.read_csv("countries.csv")
countries["Country_abbrev"] = countries["FIPS 10-4"]
stations = pd.read_csv("station-metadata.csv")

# Reading them into database
conn = sqlite3.connect("Database_temps.db")
stations.to_sql("stations", conn, if_exists = "replace", index = False)
temperatures.to_sql("temperatures", conn, if_exists = "replace", index = False)
countries.to_sql("countries", conn, if_exists = "replace", index = False)
```

##### PART2: Defining the query function and testing it.

###### The fundamental idea is to grab the columns we need in the database, use my newly learned SQL grammar. We first drop the unecessary columns before stacking and resetting index, then after some brief data cleaning and indexing, we could get our desired outcome. I observe that the running time for a dataset of this size to be approximately 20 seconds for a 8GB RAM.

```python
# Defining the function
def query_climate_database(country, year_begin, year_end, month):
    # Check the input type
    if type(country) != str:
        raise ValueError("Wrong input type: Country")
    if type(year_begin) != int or type(year_end) != int or type(month) != int:
        raise ValueError("Wrong input type: 'year_begin', 'year_end', or 'month'")
        
    cmd = \
    """
    SELECT T.*, S.LATITUDE, S.LONGITUDE, S.NAME, C.Name
    FROM stations S
    LEFT JOIN temperatures T ON T.id = S.id
    LEFT JOIN countries C ON T.Country_abbrev = C.Country_abbrev
    """
    
    df = pd.read_sql_query(cmd, conn)
    df = df.drop(["Country_abbrev", "ID"], axis = 1)
    df = df.set_index(keys=["NAME", "LATITUDE", "LONGITUDE", "Name", "Year"])
    df = df.stack()
    df = df.reset_index()
    
    # Rename and transform
    df = df.rename(columns = {"level_5":"Month", 0:"Temp", "Name":"Country"})
    df["Month"] = df["Month"].str[5:].astype(int)
    df["Temp"] = df["Temp"]/100
    df["Year"].astype(int)
    
    # Getting the country
    df_country = df[df["Country"] == country]
    
    # Getting the month and year
    df_month = df_country[df_country["Month"] == month]
    df_year = df_month[df_month["Year"] >= year_begin]
    final = df_year[df_year["Year"] <= year_end]
    
    return final

# Testing the output
India = query_climate_database("India", 1980, 2020, 1)
```
##### The output we generated matches the example perfectly

```python
India
```

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NAME</th>
      <th>LATITUDE</th>
      <th>LONGITUDE</th>
      <th>Country</th>
      <th>Year</th>
      <th>Month</th>
      <th>Temp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4024607</th>
      <td>PBO_ANANTAPUR</td>
      <td>14.583</td>
      <td>77.633</td>
      <td>India</td>
      <td>1980.0</td>
      <td>1</td>
      <td>23.48</td>
    </tr>
    <tr>
      <th>4024619</th>
      <td>PBO_ANANTAPUR</td>
      <td>14.583</td>
      <td>77.633</td>
      <td>India</td>
      <td>1981.0</td>
      <td>1</td>
      <td>24.57</td>
    </tr>
    <tr>
      <th>4024631</th>
      <td>PBO_ANANTAPUR</td>
      <td>14.583</td>
      <td>77.633</td>
      <td>India</td>
      <td>1982.0</td>
      <td>1</td>
      <td>24.19</td>
    </tr>
    <tr>
      <th>4024643</th>
      <td>PBO_ANANTAPUR</td>
      <td>14.583</td>
      <td>77.633</td>
      <td>India</td>
      <td>1983.0</td>
      <td>1</td>
      <td>23.51</td>
    </tr>
    <tr>
      <th>4024655</th>
      <td>PBO_ANANTAPUR</td>
      <td>14.583</td>
      <td>77.633</td>
      <td>India</td>
      <td>1984.0</td>
      <td>1</td>
      <td>24.81</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4111590</th>
      <td>DARJEELING</td>
      <td>27.050</td>
      <td>88.270</td>
      <td>India</td>
      <td>1983.0</td>
      <td>1</td>
      <td>5.10</td>
    </tr>
    <tr>
      <th>4111596</th>
      <td>DARJEELING</td>
      <td>27.050</td>
      <td>88.270</td>
      <td>India</td>
      <td>1986.0</td>
      <td>1</td>
      <td>6.90</td>
    </tr>
    <tr>
      <th>4111612</th>
      <td>DARJEELING</td>
      <td>27.050</td>
      <td>88.270</td>
      <td>India</td>
      <td>1994.0</td>
      <td>1</td>
      <td>8.10</td>
    </tr>
    <tr>
      <th>4111620</th>
      <td>DARJEELING</td>
      <td>27.050</td>
      <td>88.270</td>
      <td>India</td>
      <td>1995.0</td>
      <td>1</td>
      <td>5.60</td>
    </tr>
    <tr>
      <th>4111632</th>
      <td>DARJEELING</td>
      <td>27.050</td>
      <td>88.270</td>
      <td>India</td>
      <td>1997.0</td>
      <td>1</td>
      <td>5.70</td>
    </tr>
  </tbody>
</table>
<p>3152 rows Ã— 7 columns</p>
</div>



##### PART 3: Defining the plot and related function, and testing them

##### First we define a function that calculates the slope of the linear regression model. Here, some minor tweaks from the sample function in the lecture notes are necessary because insteaad of a single value, outputting a data frame would make our lives much easier. We then have to capitalize on the query function we just defined, and with that, find the parameters we need to construct the scatter mapbox

```python
# Defining the linear regression function:
def coef(data_group):
    x = data_group[["Year"]] # 2 brackets because X should be a df
    y = data_group["Temp"]   # 1 bracket because y should be a series
    LR = LinearRegression()
    LR.fit(x, y)
    data_group["Coef"] = LR.coef_[0]
    return data_group

# Defining the plot function:
def temperature_coefficient_plot(country, year_begin, year_end, month, min_obs, **kwargs):
    # Check the input type of min_obs
    if type(min_obs) != int:
        raise ValueError("Wrong input type: min_obs")
        
    stations = query_climate_database(country, year_begin, year_end, month)
    # Add count to stations
    stations["Count"] = stations.groupby('NAME')['Temp'].transform(len).astype(int)
    # Filter out the stations with more than min_obs years
    stations_trim = stations[stations["Count"] >= min_obs]
    # Calculate the slope and drop unecessary columns
    stations_trim = stations_trim.groupby('NAME').apply(coef)
    stations_sum = stations_trim.drop(["Temp", "Year", "Month", "Count"], 
                                      axis = 1).groupby(["NAME", "Country"]).apply(np.mean)
    stations_sum["Size"] = 2*np.abs(stations_sum["Coef"])
    
    # Construct the figure
    fig = px.scatter_mapbox(stations_sum, 
                        lat = "LATITUDE",
                        lon = "LONGITUDE", 
                        title = "Temperature trends in past decades",
                        **kwargs)
    fig.update_layout(title_x=0.035,
                      title_y=0.965,
                      margin={"r":0,"t":0,"l":0,"b":0})
    
    return fig
    

# Showing the figure
"""
Here, I represented the rate of increase by the numeric value of the color. The size was 
denoted by the absolute value of the coefficients. It makes the reader's life easier given 
it is interpretable how a larger one represents a faster change.
"""

fig = temperature_coefficient_plot("India", 1980, 2020, 1, 10, zoom = 3.2, 
                                   mapbox_style = "carto-positron", size = "Size",
                                   color = "Coef")
fig.show()
plotly.io.write_html(fig, "India.html")
```
{% include India.html %}


##### PART 4: Some more plots. The two plots I came up with are as follows

##### In the first plot, I hope to compare the temperature pattern in summer and winter respectively in India. To enhance its interpretability, I fit two linear models on top of the line plots, and it shows that summer temperatures seem to rise faster than winter. However, winter temperatures are subject to a significant outlier, so whether the difference is significant remains to be re-examined. 

```python
# Plot 1: Trend lines
Jan = query_climate_database("India", 1980, 2020, 1)
June = query_climate_database("India", 1980, 2020, 6)

def slope(data_group):
    x = data_group[["Year"]] # 2 brackets because X should be a df
    y = data_group["Temp"]   # 1 bracket because y should be a series
    LR = LinearRegression()
    LR.fit(x, y)
    return LR.coef_

temp_df_Jan = Jan.groupby(["NAME", "Year"])[["Year", "Temp"]].transform(np.mean)
temp_df_Jun = June.groupby(["NAME", "Year"])[["Year", "Temp"]].transform(np.mean)

LR1 = linear_model.LinearRegression()
LR1.fit(temp_df_Jan[["Year"]], temp_df_Jan["Temp"])
y_val_Jan = LR1.predict(temp_df_Jan[["Year"]])

sns.lineplot(data = temp_df_Jan, 
             x = "Year", 
             y = "Temp")
plt.scatter(temp_df_Jan["Year"], y_val_Jan, color='blue', linewidth=0.2)

LR2 = linear_model.LinearRegression()
LR2.fit(temp_df_Jun[["Year"]], temp_df_Jun["Temp"])
y_val_Jun = LR2.predict(temp_df_Jun[["Year"]])

sns.lineplot(data = temp_df_Jun, 
             x = "Year", 
             y = "Temp")
plt.scatter(temp_df_Jun["Year"], y_val_Jun, color='orange', linewidth=0.2)
plt.title("Temperature trends in Winter and Summer in India")
plt.show()
```
    
![output_5_0.png](/images/output_5_0.png)
    

##### The second plot shows how new the weather stations are. I estimate the construction date by the first year they yielded data, and by judging from the colors, it is apparent that many of the new sites are constructed in the Rocky Mountains.
```python
# Plot 2: The Z_score of the construction date
US = query_climate_database("United States", 1980, 2000, 1)
US = US.groupby("NAME")[["LATITUDE", "LONGITUDE", "Year"]].apply(np.min)
US["Z_score"] = (US["Year"] - np.mean(US["Year"]))/np.std(US["Year"])
fig2 = px.scatter_mapbox(US, 
                        lat = "LATITUDE",
                        lon = "LONGITUDE", 
                        color = "Z_score",
                        zoom = 2.7,
                        height = 600, 
                        mapbox_style="carto-positron",
                        title = "Age of weather stations in US - scaled")
fig2.show()
plotly.io.write_html(fig2, "US_stations.html")
```
{% include US_stations.html %}


##### Bonus: Anoter approach of dealing with query

##### This is my first try of solving this problem. Taken consideration that the previous equivilant function takes time reading in the data, I do believe this one is less efficient. For illustration and practice purposes, I put this at the very end.

```python
def query_climate_database(country, year_begin, year_end, month):
    # Check the input type
    if type(country) != str:
        raise ValueError("Wrong input type: Country")
    if type(year_begin) != int or type(year_end) != int or type(month) != int:
        raise ValueError("Wrong input type: 'year_begin', 'year_end', or 'month'")
        
    # Merge, stack, reset
    temperatures["FIPS 10-4"] = temperatures["ID"].str[0:2]
    temp = pd.merge(temperatures, countries, on = ["FIPS 10-4"])
    temp = temp.drop(["FIPS 10-4", "ISO 3166", "Name"], axis = 1)
    temp = temp.set_index(keys=["ID", "Year"])
    temp = temp.stack()
    temp = temp.reset_index()
    
    # Rename the columns
    temp = temp.rename(columns = {"level_2"  : "Month" , 0 : "Temperature (C)"})
    temp["Month"] = temp["Month"].str[5:].astype(int)
    
    # Find the country
    temp_stations = pd.merge(temp, stations, on = ["ID"])
    temp_stations["FIPS 10-4"] = temp_stations["ID"].str[0:2]
    temp_stations = pd.merge(temp_stations, countries, on = "FIPS 10-4")
    temp_stations = temp_stations.drop(["FIPS 10-4", "ISO 3166", "ID"], axis = 1)
    
    # Find the month
    temp_month = temp_stations[temp_stations["Month"]==month]
    temp_month = temp_month[temp_month["Year"] >= year_begin]
    temp_month = temp_month[temp_month["Year"] <= year_end]
    temp_month = temp_month[temp_month["Name"] == country]
    temp_month["Temperature (C)"] = temp_month["Temperature (C)"]/100
    temp_month = temp_month.drop("STNELEV", axis = 1)
    
    return temp_month
```

#### Yeah, that's pretty much it for this assignment. Everything seems to clear up a little bit, and stay tuned for the nest post!